{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crossme0809/whisper-tutorials/blob/main/PyDub_Spilit_Audio_for_Whisper_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **通过OpenAI Whipser API在线接口转录音频**\n"
      ],
      "metadata": {
        "id": "jR9xD-Ezn-Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --upgrade -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2n1D19XxVhW",
        "outputId": "68498e00-9e64-489c-c6d4-3b25ab894930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDzwTd7uL25b",
        "outputId": "a94f5cfb-1a8b-40a0-f440-9d72064b328e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "%pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"your-openai-api-key\""
      ],
      "metadata": {
        "id": "v-MZfNN7xZ4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# 将音频文件根据静音部分分割成块，并使用Whisper API进行语音识别的函数\n",
        "def get_large_audio_transcription_on_silence_whisper(path, export_chunk_len, prompt):\n",
        "    sound = AudioSegment.from_file(path)\n",
        "    chunks = split_on_silence(sound, min_silence_len=500, silence_thresh=sound.dBFS-14, keep_silence=500)\n",
        "\n",
        "    folder_name = \"audio-chunks\"\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "\n",
        "    # 现在重新组合这些块，使得每个部分至少有export_chunk_len长。\n",
        "    output_chunks = [chunks[0]]\n",
        "    for chunk in chunks[1:]:\n",
        "        if len(output_chunks[-1]) < export_chunk_len:\n",
        "            output_chunks[-1] += chunk\n",
        "        else:\n",
        "            # 如果最后一个输出块的长度超过目标长度， 我们可以开始一个新的块\n",
        "            output_chunks.append(chunk)\n",
        "\n",
        "    whole_text = \"\"\n",
        "    for i, audio_chunk in enumerate(output_chunks, start=1):\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.mp3\")\n",
        "        audio_chunk.export(chunk_filename, format=\"mp3\")\n",
        "\n",
        "        try:\n",
        "            audio_file = open(chunk_filename, \"rb\")\n",
        "            transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, prompt=prompt)\n",
        "            text = transcript['text']\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", str(e))\n",
        "        else:\n",
        "            text = f\"{text.capitalize()}. \"\n",
        "            print(chunk_filename, \":\", text)\n",
        "            whole_text += text\n",
        "\n",
        "    return whole_text\n",
        "\n",
        "path=\"chatgpt_whisper.mp3\"\n",
        "export_chunk_len = 90 * 1000\n",
        "prompt=\"这是一段中文视频，里面会介绍关于ChatGPT和Whisper实现语音转文字获取摘要的功能。\"\n",
        "\n",
        "audio_text = get_large_audio_transcription_on_silence_whisper(path, export_chunk_len, prompt)\n",
        "print(\"\\nAudio Full text:\", audio_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2-TGDsT-dMK",
        "outputId": "5e9555bf-07ed-43aa-f6e2-831cf6168936"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.mp3 : 大家好,在上次的影片中有稍微介绍到 如何去利用whisper将语音转换成文字 然后透过chatgpt去进行摘要 后来就有很多人问我讲说 那今天有没有办法去使用whisper的这个api 为影片来上字幕 也有人去问到讲说 诶,可是它在去使用我的这个程式的时候 里面好像有叫做ffmpeg没有办法去做安装 该怎么去做解决 以及有人去问到讲说 那whisper的api跟简映有怎样子的一个差别 好,所以这次我们在这一集的节目里面 我们去一一的去做个解答 好,所以首先来讲说呢 我们来看一下就是大家所关心的第一个问题就是 我今天有没有办法去使用whisper 来为影片来上字幕 那其实是可以的 当我们今天来讲说呢 点到这个就是whisper api的这个playground以后 其实是这个openai的这个就是api的playground以后 我们在这个documentation下面 我们可以寻找到audio的这个部分 那下面的时候呢 你可以看到讲说呢 在这里面我们可以去建立我们的这个就是转录档 那这里面讲说呢 它去吃几个参数 除了就是我们之前介绍的就是档案啦 模型之外 它另外讲说呢 有做response format 它这边呢 今天就可以从就是我们原本预设的这个json里面 我们可以改输出就是所谓的字幕档srt 甚至像是verbal json或者是vtt等这样子的一个档案 好,那我们就来看讲说呢 我们该怎么去实作这一段 所以呢 首先来讲说呢 我们去打开我们的jupyter notebook. \n",
            "audio-chunks/chunk2.mp3 : 不过上次来讲就有人提到讲说 他在自己的电脑上面去做这个程式码运行的时候 想要去把这个就是youtube影片下载下来以后去做一个转换 发现来讲说呢没有办法去做执行 主要呢原因是因为少了一个东西呢叫做ffmpeg 那ffmpeg呢它就是一个软体 你要把它给下载安装到你的自己电脑里面以后 我们今天才有办法去使用一些ytdlp的一些套件 来去进行这些youtube影片的这个下载跟做一些转换的一些动作 那如果说你没有去安装这个套件的话 那基本上来讲说呢上次的程式码会在这个地方就会产生卡关的问题 好那ffmpeg呢其实呢它的安装来讲说也不算复杂 你只要进到ffmpeg的这个官网以后呢你选择就是这个download 然后呢这边呢我们今天就可以找到就是各个作业系统所适用的一些版本 那基本上呢只要把它安装进来以后就有办法去使用这个ffmpeg去进行操作 好不过呢它的安装来讲说不算太简单 因为呢它并不是所谓的一键安装 那你必须要有些基本的电脑知识 才有办法来讲说呢去设定好这个相关的环境变数以后使用这个ffmpeg 那如果说你觉得说呢安装ffmpeg呢过于复杂的话 我们这时候呢就推荐另外一个方法 我们今天来讲说呢把我们的程式码放到我们的colab上 好那在colab来讲说呢因为就是它预设所开的vm. \n",
            "audio-chunks/chunk3.mp3 : 基本上都有预设装载这个fmpeg 所以如果说我们今天使用codelab去做这个程式运行的话 那没有任何的问题 我们简单来讲说就可以直接在上面去安装ytdlp 下载youtube的影片 并且来讲说去透过openai的这些api 去进行这个语音转文字的一个动作 所以这边来说我开了一个就是codelab jupyter notebook 我把命名叫做course221.ipynb 那这边来说有几个步骤 我们就一步一步来做 第一步来讲说我们是要去安装这个相关的一些套件 好所以这边我先打这个pip install 然后这个upgrade the pip 然后我先去做ytdlp的安装 我先去安装openai 跟去安装这个pydub 好我们这里稍微做个执行的动作 好那这时候来讲说第一次启动这个codelab的时候 它的这个地方会去给我们一个vm 所以它开始必须去创建一个vm 然后去进行这个连线 所以开始稍微比较久 那等到这个地方也开始连线以后 它就开始去运行这边的一个sale 然后这时候就会去照我们刚刚的一个步骤 我们会去下载这个pip 安装这个pip 然后下载安装这个ytdlp openai跟pydub等这些相关的一些套件 好那现在安装好以后 下面都会讲说就是要做successfully installed 所有的东西都已经安装好了 安装好以后 接下来我们就要去下载我们的youtube的影片 好那这边来讲说 我稍微是使用这个 就是codelab所提供的一个foam 也就是表单的一个机制 我把这里面的这个输入 全部去做成是一个表单. \n",
            "audio-chunks/chunk4.mp3 : 所以今天先给个序叫做下载youtube影片 然后这里发表说我们今天要去产生输出的档名 原本来讲说你要在程式区这地方去做修改 但是我已经很贴心的帮你把它做成是一个参数 所以你可以直接在右边这地方去做个修改以后 就可以产生我们的输出档案的名称 好 那我们现在这个输出的档案名称 我先把预设叫做audio 另外讲说我今天就把这个youtube的连结 先把它放进去 一样你可以在右边的这个选单里面 输入这个连结 它就会根据这个连结来下载相关的youtube的影片 最后我们就是设定我们的这些选项 比如说这地方我们要的就是audio 需要它是mp3 最后我们会去建立ytdop去下载这个物件 好 这边来讲说我们就去做个执行 来下载youtube影片 好 这影片已经下载好了 它现在叫做audio.mp3 你可以在档案区下面的时候 找到audio.mp3这样子的一个档案 接下来讲说我们要去透过whisper的api 来去将这个语音转换成是文字 但是在上一集之中我们有提到说 这个whisper api它吃的这个档案大小有限制 所以这时候我们必须把这个档案去做切割 这边来讲说我们可以使用pydub来讲说 去做这个切割的一个动作 这边来讲说我会直接就建议讲说 大家就把这个档案 每一个都把它切成就是1000秒 1000秒的话 这边它必须是1000乘上1000 大概就是100万毫秒的意思 所以这边来讲说我们今天就把这个档案 去把它切成是100万的毫秒 也就是1000秒来去做这个影片的分割 所以相当于讲说如果这个影片 它是超过20分钟的 它就可能变成说第一部影片大概是16.67分钟 第二部影片来讲说大概是3分钟左右. \n",
            "audio-chunks/chunk5.mp3 : 好,那这边来讲说呢 为了能够就是让这个切割会变得比较方便 所以我们今天讲说呢 可以去适应就是各种不同的影片的长度 那有些如果说呢是20分钟的就把它切成是两段 那如果说呢是这个就是40分钟的把它切成是三段 所以这边来讲说呢 我们就去建立一个list 然后呢接下来我们用回圈的方式去做这个切割 好,那每次切割产生出来的这个档案来讲说呢 如果说今天就把它切成是两个档案的话 就会分别输出就是output0跟output1.mp3 然后接下来来讲说呢 我们再把这个output0跟output1这个mp3 我们把它分别打开以后 我们把它加到这个叫做soultrack的list里面去 好,那我们就使用这个程式来去做影片的分割 好,那分割完以后呢 这时候呢我明年就是这个影片大概是20几分钟 所以我们就把它切成就是output0.mp3跟output1.mp3 那切割完以后呢 接下来我们就去使用这个就是openai的这个whisper api 来去做这个语音转文字的一个动作 那这边来说呢一样的呢 我就把这个就是api的一个key呢 我今天把它输出成就是一个就是parameter一个参数 你可以今天把这个参数填进去以后呢 我们今天就可以去使用这一个就是你自己的key 然后呢今天就可以把这个语音转换成是文字 好,不过呢这边为了去做这个示范 我先把我自己的一个token呢 今天把它给输入进去 好,输入进去以后呢 接下来我们就要去做这个转译的一个动作 好,那之前转译的时候呢 我们的做法是这样子 我们是呼叫这个openai.audio.transcribe. \n",
            "audio-chunks/chunk6.mp3 : 来去做这个语音转文字的一个动作 那里面来讲说呢 我们要去填几个参数 我们可以去看它的这个api 它要去给的这个参数来讲说呢 就包含这个whisper1跟我们的这个audiofile ok 那这两个东西呢 没有问题 但是呢 这一次呢 我们是要去产生字幕档出来 所以这边来讲说呢 我们要去填另外两个东西 一个呢 是我们的responseformat 好 那我们先把responseformat 我们先把它填进去 所以在下面的时候呢 我就填一段叫responseformat等于srt ok 那这样子来讲说呢 我今天就可以把这个输出 输出成是我的一个字幕档 好 但是呢 除了就是这个responseformat之外呢 它下面来讲说呢 还有一段叫做prompt 好 那prompt是这个提示词 那这个prompt是什么意思呢 这地方来讲说呢 我们可以去参考另外一段的这个就是documentation 叫做speech-to-text 好 那在里面的时候呢 它要去解释一下什么叫做prompt 好 那prompt呢 基本上讲来讲说呢 它跟这个chairgpt的这个prompt呢 稍微有点不太一样的是 呃 我们知道讲说呢 今天在讲这个语言的时候 我们常常呢 会因为各个不同的领域跟主题 好 所以呢 同样的音可能是不同的意思 好 所以比如说我先讲两个字好了 比如说像是城堡 好 那比如说呢 今天这地方说呢 这个城堡 如果是在讲这个金融的话 它可能就是跟保险有关 就比如说 诶 我今天要不要去乘坐这个保险 我们简称用城堡两个字来代表. \n",
            "audio-chunks/chunk7.mp3 : 那如果说我今天是在讲住的地方的话 它可能就是比如说山上的城堡啦 或者是欧洲的一些城堡啦 那同样是城堡 那这个地方来讲说转译的结果不同 好,所以在prompting里面来讲说 今天可以透过prompt 来去提示来讲说 跟他讲说 这一个语音大概是讲哪一个的主题 只要这个主题够明确的话 它今天转译的效果就会变得比较好一些 好,所以这时候我们来看一下说 我们该怎样去下我们的这个prompt这个词 好,所以这时候我们再回到我们的这个codelab里面 我们后面再加上一段叫prompt 等于 好,这边来讲说我输一段文字 叫做这是一段关于吴淡如与joeman讨论台湾人是否应该买房的一个访谈 好,那我们加进去以后这时候我们就大功告成 我们就产生了就是我们用的model是whisper1 然后这是我们的一个audio的file 那我刚刚是把这个audio file是从我们的这个list里面来讲说 一一地取出以后去做这个转换的动作 输出的是我们的这个就是字幕档 最后来讲说这里边我们加上一个提示 告诉他讲说这是一个关于买房的一个讨论 叫他根据就是这样子的一个主题去进行转译的一个动作 那我们就把这次每次产生出来的这个就是转录的这个脚本 最后把它放到叫做transcripts底线ary这个list之中 好,这边讲说我们去执行一下 好,转译完了,所以这时候我们就会把所有的这个脚本放到transcripts底线ary这个list之中 我们先把这里面就是第一段把它列出来 所以我们这里面再打一个就是中括号的一个0 诶,你会发现他已经把这个就是字幕档转出来了 那同时来讲说呢,今天这一方还有加上我们的这个开始时间戳跟结束的一个时间戳. \n",
            "audio-chunks/chunk8.mp3 : 好 那为了能够更完美的去呈现字幕档 所以这边我们使用这个print 那它可以根据这个换行符号去进行断行的动作 所以你会发现 这时候它的确就把字幕档 这半数就是把它全部的给转出来 那转的效果来讲说 我觉得还相当的一个不错 所以像这地方 比如说一开始的时候 joeman讲的就是金融世界的风险真的很大 我花过130万整修一间套房 因为那个韩国学生把里面弄到就是 像二次世界大战之后被摧毁的一个废墟 其实转录的效果非常之好 好 那这边来讲说是第一段的文字 那这边来说 我先把它给清除掉 然后我们再来看第二段的文字 ok 这一方我们就打这个transcripts底线 ary 然后1 好 这时候来讲说 就会从第二段这一半数 开始去做一个转录的动作 那效果来讲说 也是相当的一个不错 好 可是这时候就有个问题啦 因为我们一开始的时候把这个影片 我们是做一个分段的切割 然后我们接下来讲说 我们是做这个分段的转录 那如果说我们今天想要把这两个字幕档 今天把它给合并在一起的话 这时候我们该怎么做 这时候来讲说 我们就要去借助其他套件的一个帮忙 好 那使用哪些套件呢 这时候很简单的 我们就是直接把这个问题 丢给chetgbt去进行回答 好 这时候我们就把它切换到这个chetgbt 来问chetgbt来讲说 如何去合并两个字幕档. \n",
            "audio-chunks/chunk9.mp3 : 好,这边我就直接打下我的叙述 就是如何使用python的pysrt套件 它是做一个字幕档专门处理的一个套件 来将两个srt文件合并 并且去更改这个srt文件的一个时间戳 好,这边我们来去做一个执行 好,这时候它就劈哩啪啦回了我一大堆 告诉我讲说,我必须先去安装这个pysrt套件 好,所以我们这时候就复制这个程式码 然后我们到这个gpt notebook里面来 好,那这边它讲说我就是去安装pysrt 所以对面就打就是金碳号 然后ppstore pysrt 我们来做一个安装 然后安装完以后呢 接下来讲说我们的第二步就是 我们要去把这个srt 今天把它给读成是就是这个pysrt的这个物件 好,这边它说我们也是复制这个代码 然后呢我们就把这个代码呢 今天把它就是给贴过来 好,不过呢因为我们刚刚来讲说呢 所产生的这两个就是字幕呢 它们现在是一个文字 那所以如果说我今天想要直接把它给读进来的话 我不用打这个open的方法 我把它改成叫做from the same string 好,那这边来说呢第一段呢就是什么 就是我们的这个transcript ary0 我把它带进来 好,那第二段呢就是什么 就是同样的我们就是复制这一段 然后直接把它改成什么 就是transcript这个是ary的1 好,这时候我们今天就有就是两段的subtitle 好,所以这边就是第一段的subtitle 跟就是我们这个就是第二段的subtitle 然后都会分别就是放到就是这两个就是不同的一个物件 好,那把它放到物件以后呢 接下来讲说呢我们就可以把这两个物件呢 把它去做一个就是结合的一个动作. \n",
            "audio-chunks/chunk10.mp3 : 可是在做字结合的时候必须要考虑到一件事情 就是第一段来讲说它已经是先播过1000秒 然后才去播第二段 所以第二段的时间必须要先去增加1000秒 这时候我们来看一下说 如何去为第二段的字幕增加1000秒 这很简单 我们先去建立一个1000秒的物件 我们打叫做shift 然后打叫做time 等于pysrt 然后这一方来讲说我们先去增加叫做subrib 这个就是time 那这边来讲说我们打叫做seconds 等于1000 ok 这时候我们建立一个就是1000秒的物件 然后最后来讲说 假设我们想要让这个subtitle2 这地方都往后去shift1000秒的话 我们可以这样做 我们打from sub 然后这个就是我们的subtitle2 ok 然后接下来讲说 我们今天就针对这里面的每一个sub 我们的start 等于就是我们的sub.start 我们加上这个就是shift ok 然后这边来讲说 我们的end也是一样 我们去做这样的一个调整 这时候来讲说 我们今天就可以去确保讲说 第二段的时间都会往后去shift1000秒 好 然后去做完这个修改 好 这时候这地方就大功告成 我们这时候就让第二段的影片 已经往后都shift了1000秒左右 好 那这怎么做合并呢 我们再回来看到这个qgbt 就是说你也可以透过extend这样子的一个指令 来去做这个合并. \n",
            "audio-chunks/chunk11.mp3 : Ok,所以这时候我们就把这个程式码呢 我们先把它给复制过来 复制过来以后呢 这边来讲说我们就打这个叫做subtitles1 然后点instance subtitles2 ok,我们这时候去做这个合并的动作 那合并完以后呢 最后呢我们可以把这个答案呢 我们先把它做个储存 所以我们就打这个叫做subtitles1.save 我们就把它叫做这个叫做merge的subtitles.srt 好,这时候我们做这个储存 做完这个储存以后呢 这时候呢在我们的答案区里面 就可以看到这个merge subtitles.srt 好,这时候我们来去检视一下这个档案 我们把它打开来 好,这时候就可以放来讲说呢 这个地方就是两个字幕档 我们先把它给合并在一起 那这边呢是第一段 那后面这地方来讲说呢 这个地方是第二段 那看起来来讲说呢 这个时间戳上面呢 看起来就是第二段来讲说呢 的确都有往后去shift 大概就是1000秒左右 好,可是呢这边来讲说呢 会有一段有问题 在哪一段有问题呢 我们这边来讲说呢 我们去找到就是差不多16分钟的 那个接点好了 所以大概就是在16分钟40秒的一个部分 我们找一下 ok 那其实这边来讲说呢 你可以看到讲说呢 这上面的这个编号呢是这样子 就是 这个123456呢 这边来讲说呢 这个是第二段 它的开头编号呢是这个123456 从1开始做编号 第一段呢也是从这个1开始做这个编号 所以这边我们可以看到讲说呢 这边是635 然后这边这个是1 主要这边讲说呢 这是第一段的最后的结尾 然后这地方是第二段的一个开头 好那这个序号乱掉有没有什么任何问题 其实并没有任何的问题 所以他去接这个东西的时候呢 这个序号你是可以忽略不计的. \n",
            "audio-chunks/chunk12.mp3 : 只是来讲说,这边会稍微来讲说有个问题 你可以看到说在第一段的这个第635的这个地方的时候 它这边的这个文字就是前不久就看到一个误解 好,那这边的这个其实时间的是16分38秒 但是结束时间的是16分58秒 那这有什么样的问题呢? 其实我们知道讲说每个影片它最大的一个长度应该是1000秒 所以如果说今天换算下来讲说就是这个影片来讲说 最长的一个时间应该是到16分40秒左右 但是它在做一个转译的时候会有一些小问题 所以最后的这个时间戳呢 这地方必须要做一个修改的动作 这样子来讲说我们今天才不会就是让两个字幕会产生时间重复的问题 那如果说有时间重复的问题的话 有一些上字幕的软体这时候就会把它判定成是一个错误 让你这个字幕都没有办法就是上载上去 好,所以这时候我们必须把这个第一段的问题稍微修掉 那我们该怎么去做这个修改呢? 我们来看一下以下的一个范例 这时候方法其实可以很简单 就是说我们其实只要让每部影片 它最后的这个截温时间是小于16分40秒就好 好,所以这时候我可以怎么做呢? 我可以设定一个就是最大的一个限制 我们就把这个东西把它叫做max time 好,它在讲说最大就是1000秒 好,所以这时候我们就针对就是我们这个字幕 比如说for sub in this subtitles1 好,我们把这里面的这个sub我们把这个拿出来 接下来我们去做这个时间的调整 所以我们就打这个sub start等于什么?. \n",
            "audio-chunks/chunk13.mp3 : 好,就是说如果这个start呢 if这个就是它的这个就是start 它是小于我们的这个max time的话 好,这里发现说呢就是这个sub start 那else的话,这一方我们就设为就是我们的这个max time ok,所以就是说如果我今天小于这个就是1000秒的话 那就是以这个时间为主 但是它超过的话我们就是最多就是1000秒 好,那这边是设这个start的一个部分 然后接下来我们就去设这个end的一个部分 好,我们今天也去做这样的一个修改 好,所以我们把这个start呢 这边要说我们去改成就是这个end 好,这时候呢我们去做完这个修改以后 我们就可以去修改完这整个的一个时间 好,那这时候来讲说呢 因为这个subtitle1呢 刚刚已经去做这个extend修改过了 所以这一段我们必须再从这一段呢 再去做个重新的执行 所以我们就把这个transcript ary的0变成subtitle1 然后就是这个transcript ary的1 然后变subtitle2我们做个执行 执行完以后呢我们就是限制这个subtitle1的这个就是时间 好,那限制完这个时间以后呢 接下来讲说呢就是我们的第二部影片呢 就是加上这个1000秒 那最后来说呢,透过这个extend 然后我们这时候呢再把这个档案呢 我们再把它回存回去 好,所以这时候呢回存回去以后呢 我们再打开一次这个就是merge的这个srt 好,接下来讲说呢 我们去找到就是接序的一个部分 大概在600这个地方的这个部分 好,找一下 好,这时候来讲说呢就是第一段来讲说呢 最透的一个时间就变成是这个16分38秒到16分的40秒 然后第二段呢就会从这个16分的40秒这个地方开始起. \n",
            "audio-chunks/chunk14.mp3 : 所以这时候这个字幕就没有问题了 那字幕没有问题以后呢 接下来我们就把这个字幕我们把它下载下来 我们来看一看这个字幕我们今天把它上上去以后 它大概的一个效果如何 我们来看一下 那这边来讲说我们来用这个简易上一下字幕 来看一下这个地方的一个成果 那简易来讲说是一个很知名的一个软体 那现在有很多人去使用它来讲说去做免费上字幕的一个动作 那我们先来讲说因为要去介绍简易嘛 所以我们先用它来去上一下字幕 我们先把刚刚whisper转出来的这个字幕上上去 我们先来看一下效果如何 之后呢再透过这个简易的这个就是智能字幕 我们也去做一个版本出来 我们再来去做一个比较 好那这边呢你必须先去下载这个就是简易 下载下来以后呢这时候我们就打开这个就是简易专业版 然后我们开始做这个创作 首先必须导入我们的这个视频 所以我们就是这个导入以后选择这个jomain的这个mp4 我是先透过ytdlp然后先把它下载到就是我的本地端啦 所以这边讲说呢这本地端会有个mp4的一个档案 那之前的所教的是mp3的格式 所以如果说你要去下载mp4的话 必须把就是ytdlp的参数 改成就是下载mp4的一个参数 好下载完以后呢我们就把这个影片呢 就把它给拖到这个地方来 ok这边我们看到它的这个就是原始的这个影片 接下来呢这边我们必须把这个文本呢 把它给上载上去 所以我们选的就是文本 然后这边呢下面我们选的就是本地字幕 我们去导入srt的档案 我们把刚刚的这个就是merge subtitle这个srt 我们先把它给上载上去. \n",
            "audio-chunks/chunk15.mp3 : 上载上去以后呢 我们就把这个文字档呢 我们要把它导入过来 ok切过来 好 这时候就导入了就是我们的这个就是文字 那导入这个文字以后呢 因为这个地方他原本就有上这个字幕嘛 然后这个颜色也不是很明显 所以就把这个颜色的这个字幕呢稍微改一下 我们把它改成就是黄色的好了 这边改一下 ok 然后这时候我们来去做这个播放 来去做这个比较 ok 所以这边我开始做这个播放 所以你们发现其实呢 whisper api做的这个效果呢真的是非常之好 好 那这边来讲说呢 去试过这个whisper api以后呢 接下来讲说这个简易呢 他自己有去提供这个就是智能字幕 透过ai上字幕 那他的呢是免费的 所以我们来看一下说这个简易的效果到底好不好 所以这边呢 如果说呢 就使用这个简易的智能字幕的话 我们就选择智能字幕 然后这边呢 我们讲说今天去让他去做这个字幕的识别 然后我们按下这个开始识别以后 让他来讲说呢 去做这个就是转换的一个动作 我们按一下 好 那现在已经转换完以后呢 这边呢 我也改一下就是这个字幕的这个颜色 所以这边说你看到这个就是简体中文的来讲说呢 就是简易转出来的这个结果 好 这边说呢 我们稍微去播放一下来去比较一下说他跟这个whisper api的一个差别 我们这一方去做个播放 ok 所以发现说呢 就是简易呢 其实效果也还不错 那只是来讲说呢 他第一个呢 是有产生这个简体中文的一个输出 第二个来讲说呢 其实在一些专有名词上面的一个翻译上面来讲说呢 其实做的并不是特别的好. \n",
            "audio-chunks/chunk16.mp3 : 所以最后用起来的时候,我个人的感觉是这样子 如果今天对方说你要准确、快速地上字幕的话 whisper api是一个非常好的选择 这对方来讲说,它还可以透过prompt 来去提示今天是哪一个的主题 让他可以去做更精准的一个转录 它的优点很多,但是唯一的缺点就是它要钱 但是费用也不贵 大概是一个小时的影片,大概只要收10块钱的台币 那这算是什么概念呢? 如果你用过云端转录的一些服务 比如说我们讲雅庭竹子高号 它是收一个小时要100块 所以基本上来讲说,whisper api的横空出世 基本上是打趴了这一群原本做语音转文字的厂商 简易来讲说也很好 只是来讲说它有几个缺点 第一个是说它的翻译出来的结果 这一方来讲说是简体中文 当然你可以去做繁体中文的输出 但是用字遣词跟你平常所看到的 可能会稍微有一点点的一个不同 第二个来讲说,因为它没有办法根据domain跟主题 来让它去做一个比较精准的一些转录 所以在讲特定主题的时候 那个专有名词的翻译 还是会稍稍来讲说会有一些误差存在 第三个来讲说,其实它跟whisper api来讲说 它们最大的一个差别就是. \n",
            "audio-chunks/chunk17.mp3 : 一个是api 所以如果说你今天想要去做大量的这个转入作文做这个语音分析的话 whisperapi是比较好的选择 那剪影的话就必须一支一支的影片 透过手动上载的一个方式再把字幕档拿出来 好所以这些来讲说呢大概就是这个就是whisperapi跟剪影的一个差别 但剪影呢来讲说呢有个很明显的好处就是 它不用钱是免费的 所以如果说今天你愿意花的时间 然后呢这地方你想要免费的去得到字幕的结果的话 那还是可以把剪影当成是一个好的上字幕的一个选择 好那以上来讲说呢就是我们今天对这个whisperapi 去如何去把这个就是语音转换成是字幕档的一个介绍 也去做了一些它跟剪影的一些相关的一些比较 那希望今天这个主题你喜欢 那如果说喜欢的话呢请就是帮我做这个订阅跟分享 谢谢. \n",
            "\n",
            "Audio Full text: 大家好,在上次的影片中有稍微介绍到 如何去利用whisper将语音转换成文字 然后透过chatgpt去进行摘要 后来就有很多人问我讲说 那今天有没有办法去使用whisper的这个api 为影片来上字幕 也有人去问到讲说 诶,可是它在去使用我的这个程式的时候 里面好像有叫做ffmpeg没有办法去做安装 该怎么去做解决 以及有人去问到讲说 那whisper的api跟简映有怎样子的一个差别 好,所以这次我们在这一集的节目里面 我们去一一的去做个解答 好,所以首先来讲说呢 我们来看一下就是大家所关心的第一个问题就是 我今天有没有办法去使用whisper 来为影片来上字幕 那其实是可以的 当我们今天来讲说呢 点到这个就是whisper api的这个playground以后 其实是这个openai的这个就是api的playground以后 我们在这个documentation下面 我们可以寻找到audio的这个部分 那下面的时候呢 你可以看到讲说呢 在这里面我们可以去建立我们的这个就是转录档 那这里面讲说呢 它去吃几个参数 除了就是我们之前介绍的就是档案啦 模型之外 它另外讲说呢 有做response format 它这边呢 今天就可以从就是我们原本预设的这个json里面 我们可以改输出就是所谓的字幕档srt 甚至像是verbal json或者是vtt等这样子的一个档案 好,那我们就来看讲说呢 我们该怎么去实作这一段 所以呢 首先来讲说呢 我们去打开我们的jupyter notebook. 不过上次来讲就有人提到讲说 他在自己的电脑上面去做这个程式码运行的时候 想要去把这个就是youtube影片下载下来以后去做一个转换 发现来讲说呢没有办法去做执行 主要呢原因是因为少了一个东西呢叫做ffmpeg 那ffmpeg呢它就是一个软体 你要把它给下载安装到你的自己电脑里面以后 我们今天才有办法去使用一些ytdlp的一些套件 来去进行这些youtube影片的这个下载跟做一些转换的一些动作 那如果说你没有去安装这个套件的话 那基本上来讲说呢上次的程式码会在这个地方就会产生卡关的问题 好那ffmpeg呢其实呢它的安装来讲说也不算复杂 你只要进到ffmpeg的这个官网以后呢你选择就是这个download 然后呢这边呢我们今天就可以找到就是各个作业系统所适用的一些版本 那基本上呢只要把它安装进来以后就有办法去使用这个ffmpeg去进行操作 好不过呢它的安装来讲说不算太简单 因为呢它并不是所谓的一键安装 那你必须要有些基本的电脑知识 才有办法来讲说呢去设定好这个相关的环境变数以后使用这个ffmpeg 那如果说你觉得说呢安装ffmpeg呢过于复杂的话 我们这时候呢就推荐另外一个方法 我们今天来讲说呢把我们的程式码放到我们的colab上 好那在colab来讲说呢因为就是它预设所开的vm. 基本上都有预设装载这个fmpeg 所以如果说我们今天使用codelab去做这个程式运行的话 那没有任何的问题 我们简单来讲说就可以直接在上面去安装ytdlp 下载youtube的影片 并且来讲说去透过openai的这些api 去进行这个语音转文字的一个动作 所以这边来说我开了一个就是codelab jupyter notebook 我把命名叫做course221.ipynb 那这边来说有几个步骤 我们就一步一步来做 第一步来讲说我们是要去安装这个相关的一些套件 好所以这边我先打这个pip install 然后这个upgrade the pip 然后我先去做ytdlp的安装 我先去安装openai 跟去安装这个pydub 好我们这里稍微做个执行的动作 好那这时候来讲说第一次启动这个codelab的时候 它的这个地方会去给我们一个vm 所以它开始必须去创建一个vm 然后去进行这个连线 所以开始稍微比较久 那等到这个地方也开始连线以后 它就开始去运行这边的一个sale 然后这时候就会去照我们刚刚的一个步骤 我们会去下载这个pip 安装这个pip 然后下载安装这个ytdlp openai跟pydub等这些相关的一些套件 好那现在安装好以后 下面都会讲说就是要做successfully installed 所有的东西都已经安装好了 安装好以后 接下来我们就要去下载我们的youtube的影片 好那这边来讲说 我稍微是使用这个 就是codelab所提供的一个foam 也就是表单的一个机制 我把这里面的这个输入 全部去做成是一个表单. 所以今天先给个序叫做下载youtube影片 然后这里发表说我们今天要去产生输出的档名 原本来讲说你要在程式区这地方去做修改 但是我已经很贴心的帮你把它做成是一个参数 所以你可以直接在右边这地方去做个修改以后 就可以产生我们的输出档案的名称 好 那我们现在这个输出的档案名称 我先把预设叫做audio 另外讲说我今天就把这个youtube的连结 先把它放进去 一样你可以在右边的这个选单里面 输入这个连结 它就会根据这个连结来下载相关的youtube的影片 最后我们就是设定我们的这些选项 比如说这地方我们要的就是audio 需要它是mp3 最后我们会去建立ytdop去下载这个物件 好 这边来讲说我们就去做个执行 来下载youtube影片 好 这影片已经下载好了 它现在叫做audio.mp3 你可以在档案区下面的时候 找到audio.mp3这样子的一个档案 接下来讲说我们要去透过whisper的api 来去将这个语音转换成是文字 但是在上一集之中我们有提到说 这个whisper api它吃的这个档案大小有限制 所以这时候我们必须把这个档案去做切割 这边来讲说我们可以使用pydub来讲说 去做这个切割的一个动作 这边来讲说我会直接就建议讲说 大家就把这个档案 每一个都把它切成就是1000秒 1000秒的话 这边它必须是1000乘上1000 大概就是100万毫秒的意思 所以这边来讲说我们今天就把这个档案 去把它切成是100万的毫秒 也就是1000秒来去做这个影片的分割 所以相当于讲说如果这个影片 它是超过20分钟的 它就可能变成说第一部影片大概是16.67分钟 第二部影片来讲说大概是3分钟左右. 好,那这边来讲说呢 为了能够就是让这个切割会变得比较方便 所以我们今天讲说呢 可以去适应就是各种不同的影片的长度 那有些如果说呢是20分钟的就把它切成是两段 那如果说呢是这个就是40分钟的把它切成是三段 所以这边来讲说呢 我们就去建立一个list 然后呢接下来我们用回圈的方式去做这个切割 好,那每次切割产生出来的这个档案来讲说呢 如果说今天就把它切成是两个档案的话 就会分别输出就是output0跟output1.mp3 然后接下来来讲说呢 我们再把这个output0跟output1这个mp3 我们把它分别打开以后 我们把它加到这个叫做soultrack的list里面去 好,那我们就使用这个程式来去做影片的分割 好,那分割完以后呢 这时候呢我明年就是这个影片大概是20几分钟 所以我们就把它切成就是output0.mp3跟output1.mp3 那切割完以后呢 接下来我们就去使用这个就是openai的这个whisper api 来去做这个语音转文字的一个动作 那这边来说呢一样的呢 我就把这个就是api的一个key呢 我今天把它输出成就是一个就是parameter一个参数 你可以今天把这个参数填进去以后呢 我们今天就可以去使用这一个就是你自己的key 然后呢今天就可以把这个语音转换成是文字 好,不过呢这边为了去做这个示范 我先把我自己的一个token呢 今天把它给输入进去 好,输入进去以后呢 接下来我们就要去做这个转译的一个动作 好,那之前转译的时候呢 我们的做法是这样子 我们是呼叫这个openai.audio.transcribe. 来去做这个语音转文字的一个动作 那里面来讲说呢 我们要去填几个参数 我们可以去看它的这个api 它要去给的这个参数来讲说呢 就包含这个whisper1跟我们的这个audiofile ok 那这两个东西呢 没有问题 但是呢 这一次呢 我们是要去产生字幕档出来 所以这边来讲说呢 我们要去填另外两个东西 一个呢 是我们的responseformat 好 那我们先把responseformat 我们先把它填进去 所以在下面的时候呢 我就填一段叫responseformat等于srt ok 那这样子来讲说呢 我今天就可以把这个输出 输出成是我的一个字幕档 好 但是呢 除了就是这个responseformat之外呢 它下面来讲说呢 还有一段叫做prompt 好 那prompt是这个提示词 那这个prompt是什么意思呢 这地方来讲说呢 我们可以去参考另外一段的这个就是documentation 叫做speech-to-text 好 那在里面的时候呢 它要去解释一下什么叫做prompt 好 那prompt呢 基本上讲来讲说呢 它跟这个chairgpt的这个prompt呢 稍微有点不太一样的是 呃 我们知道讲说呢 今天在讲这个语言的时候 我们常常呢 会因为各个不同的领域跟主题 好 所以呢 同样的音可能是不同的意思 好 所以比如说我先讲两个字好了 比如说像是城堡 好 那比如说呢 今天这地方说呢 这个城堡 如果是在讲这个金融的话 它可能就是跟保险有关 就比如说 诶 我今天要不要去乘坐这个保险 我们简称用城堡两个字来代表. 那如果说我今天是在讲住的地方的话 它可能就是比如说山上的城堡啦 或者是欧洲的一些城堡啦 那同样是城堡 那这个地方来讲说转译的结果不同 好,所以在prompting里面来讲说 今天可以透过prompt 来去提示来讲说 跟他讲说 这一个语音大概是讲哪一个的主题 只要这个主题够明确的话 它今天转译的效果就会变得比较好一些 好,所以这时候我们来看一下说 我们该怎样去下我们的这个prompt这个词 好,所以这时候我们再回到我们的这个codelab里面 我们后面再加上一段叫prompt 等于 好,这边来讲说我输一段文字 叫做这是一段关于吴淡如与joeman讨论台湾人是否应该买房的一个访谈 好,那我们加进去以后这时候我们就大功告成 我们就产生了就是我们用的model是whisper1 然后这是我们的一个audio的file 那我刚刚是把这个audio file是从我们的这个list里面来讲说 一一地取出以后去做这个转换的动作 输出的是我们的这个就是字幕档 最后来讲说这里边我们加上一个提示 告诉他讲说这是一个关于买房的一个讨论 叫他根据就是这样子的一个主题去进行转译的一个动作 那我们就把这次每次产生出来的这个就是转录的这个脚本 最后把它放到叫做transcripts底线ary这个list之中 好,这边讲说我们去执行一下 好,转译完了,所以这时候我们就会把所有的这个脚本放到transcripts底线ary这个list之中 我们先把这里面就是第一段把它列出来 所以我们这里面再打一个就是中括号的一个0 诶,你会发现他已经把这个就是字幕档转出来了 那同时来讲说呢,今天这一方还有加上我们的这个开始时间戳跟结束的一个时间戳. 好 那为了能够更完美的去呈现字幕档 所以这边我们使用这个print 那它可以根据这个换行符号去进行断行的动作 所以你会发现 这时候它的确就把字幕档 这半数就是把它全部的给转出来 那转的效果来讲说 我觉得还相当的一个不错 所以像这地方 比如说一开始的时候 joeman讲的就是金融世界的风险真的很大 我花过130万整修一间套房 因为那个韩国学生把里面弄到就是 像二次世界大战之后被摧毁的一个废墟 其实转录的效果非常之好 好 那这边来讲说是第一段的文字 那这边来说 我先把它给清除掉 然后我们再来看第二段的文字 ok 这一方我们就打这个transcripts底线 ary 然后1 好 这时候来讲说 就会从第二段这一半数 开始去做一个转录的动作 那效果来讲说 也是相当的一个不错 好 可是这时候就有个问题啦 因为我们一开始的时候把这个影片 我们是做一个分段的切割 然后我们接下来讲说 我们是做这个分段的转录 那如果说我们今天想要把这两个字幕档 今天把它给合并在一起的话 这时候我们该怎么做 这时候来讲说 我们就要去借助其他套件的一个帮忙 好 那使用哪些套件呢 这时候很简单的 我们就是直接把这个问题 丢给chetgbt去进行回答 好 这时候我们就把它切换到这个chetgbt 来问chetgbt来讲说 如何去合并两个字幕档. 好,这边我就直接打下我的叙述 就是如何使用python的pysrt套件 它是做一个字幕档专门处理的一个套件 来将两个srt文件合并 并且去更改这个srt文件的一个时间戳 好,这边我们来去做一个执行 好,这时候它就劈哩啪啦回了我一大堆 告诉我讲说,我必须先去安装这个pysrt套件 好,所以我们这时候就复制这个程式码 然后我们到这个gpt notebook里面来 好,那这边它讲说我就是去安装pysrt 所以对面就打就是金碳号 然后ppstore pysrt 我们来做一个安装 然后安装完以后呢 接下来讲说我们的第二步就是 我们要去把这个srt 今天把它给读成是就是这个pysrt的这个物件 好,这边它说我们也是复制这个代码 然后呢我们就把这个代码呢 今天把它就是给贴过来 好,不过呢因为我们刚刚来讲说呢 所产生的这两个就是字幕呢 它们现在是一个文字 那所以如果说我今天想要直接把它给读进来的话 我不用打这个open的方法 我把它改成叫做from the same string 好,那这边来说呢第一段呢就是什么 就是我们的这个transcript ary0 我把它带进来 好,那第二段呢就是什么 就是同样的我们就是复制这一段 然后直接把它改成什么 就是transcript这个是ary的1 好,这时候我们今天就有就是两段的subtitle 好,所以这边就是第一段的subtitle 跟就是我们这个就是第二段的subtitle 然后都会分别就是放到就是这两个就是不同的一个物件 好,那把它放到物件以后呢 接下来讲说呢我们就可以把这两个物件呢 把它去做一个就是结合的一个动作. 可是在做字结合的时候必须要考虑到一件事情 就是第一段来讲说它已经是先播过1000秒 然后才去播第二段 所以第二段的时间必须要先去增加1000秒 这时候我们来看一下说 如何去为第二段的字幕增加1000秒 这很简单 我们先去建立一个1000秒的物件 我们打叫做shift 然后打叫做time 等于pysrt 然后这一方来讲说我们先去增加叫做subrib 这个就是time 那这边来讲说我们打叫做seconds 等于1000 ok 这时候我们建立一个就是1000秒的物件 然后最后来讲说 假设我们想要让这个subtitle2 这地方都往后去shift1000秒的话 我们可以这样做 我们打from sub 然后这个就是我们的subtitle2 ok 然后接下来讲说 我们今天就针对这里面的每一个sub 我们的start 等于就是我们的sub.start 我们加上这个就是shift ok 然后这边来讲说 我们的end也是一样 我们去做这样的一个调整 这时候来讲说 我们今天就可以去确保讲说 第二段的时间都会往后去shift1000秒 好 然后去做完这个修改 好 这时候这地方就大功告成 我们这时候就让第二段的影片 已经往后都shift了1000秒左右 好 那这怎么做合并呢 我们再回来看到这个qgbt 就是说你也可以透过extend这样子的一个指令 来去做这个合并. Ok,所以这时候我们就把这个程式码呢 我们先把它给复制过来 复制过来以后呢 这边来讲说我们就打这个叫做subtitles1 然后点instance subtitles2 ok,我们这时候去做这个合并的动作 那合并完以后呢 最后呢我们可以把这个答案呢 我们先把它做个储存 所以我们就打这个叫做subtitles1.save 我们就把它叫做这个叫做merge的subtitles.srt 好,这时候我们做这个储存 做完这个储存以后呢 这时候呢在我们的答案区里面 就可以看到这个merge subtitles.srt 好,这时候我们来去检视一下这个档案 我们把它打开来 好,这时候就可以放来讲说呢 这个地方就是两个字幕档 我们先把它给合并在一起 那这边呢是第一段 那后面这地方来讲说呢 这个地方是第二段 那看起来来讲说呢 这个时间戳上面呢 看起来就是第二段来讲说呢 的确都有往后去shift 大概就是1000秒左右 好,可是呢这边来讲说呢 会有一段有问题 在哪一段有问题呢 我们这边来讲说呢 我们去找到就是差不多16分钟的 那个接点好了 所以大概就是在16分钟40秒的一个部分 我们找一下 ok 那其实这边来讲说呢 你可以看到讲说呢 这上面的这个编号呢是这样子 就是 这个123456呢 这边来讲说呢 这个是第二段 它的开头编号呢是这个123456 从1开始做编号 第一段呢也是从这个1开始做这个编号 所以这边我们可以看到讲说呢 这边是635 然后这边这个是1 主要这边讲说呢 这是第一段的最后的结尾 然后这地方是第二段的一个开头 好那这个序号乱掉有没有什么任何问题 其实并没有任何的问题 所以他去接这个东西的时候呢 这个序号你是可以忽略不计的. 只是来讲说,这边会稍微来讲说有个问题 你可以看到说在第一段的这个第635的这个地方的时候 它这边的这个文字就是前不久就看到一个误解 好,那这边的这个其实时间的是16分38秒 但是结束时间的是16分58秒 那这有什么样的问题呢? 其实我们知道讲说每个影片它最大的一个长度应该是1000秒 所以如果说今天换算下来讲说就是这个影片来讲说 最长的一个时间应该是到16分40秒左右 但是它在做一个转译的时候会有一些小问题 所以最后的这个时间戳呢 这地方必须要做一个修改的动作 这样子来讲说我们今天才不会就是让两个字幕会产生时间重复的问题 那如果说有时间重复的问题的话 有一些上字幕的软体这时候就会把它判定成是一个错误 让你这个字幕都没有办法就是上载上去 好,所以这时候我们必须把这个第一段的问题稍微修掉 那我们该怎么去做这个修改呢? 我们来看一下以下的一个范例 这时候方法其实可以很简单 就是说我们其实只要让每部影片 它最后的这个截温时间是小于16分40秒就好 好,所以这时候我可以怎么做呢? 我可以设定一个就是最大的一个限制 我们就把这个东西把它叫做max time 好,它在讲说最大就是1000秒 好,所以这时候我们就针对就是我们这个字幕 比如说for sub in this subtitles1 好,我们把这里面的这个sub我们把这个拿出来 接下来我们去做这个时间的调整 所以我们就打这个sub start等于什么?. 好,就是说如果这个start呢 if这个就是它的这个就是start 它是小于我们的这个max time的话 好,这里发现说呢就是这个sub start 那else的话,这一方我们就设为就是我们的这个max time ok,所以就是说如果我今天小于这个就是1000秒的话 那就是以这个时间为主 但是它超过的话我们就是最多就是1000秒 好,那这边是设这个start的一个部分 然后接下来我们就去设这个end的一个部分 好,我们今天也去做这样的一个修改 好,所以我们把这个start呢 这边要说我们去改成就是这个end 好,这时候呢我们去做完这个修改以后 我们就可以去修改完这整个的一个时间 好,那这时候来讲说呢 因为这个subtitle1呢 刚刚已经去做这个extend修改过了 所以这一段我们必须再从这一段呢 再去做个重新的执行 所以我们就把这个transcript ary的0变成subtitle1 然后就是这个transcript ary的1 然后变subtitle2我们做个执行 执行完以后呢我们就是限制这个subtitle1的这个就是时间 好,那限制完这个时间以后呢 接下来讲说呢就是我们的第二部影片呢 就是加上这个1000秒 那最后来说呢,透过这个extend 然后我们这时候呢再把这个档案呢 我们再把它回存回去 好,所以这时候呢回存回去以后呢 我们再打开一次这个就是merge的这个srt 好,接下来讲说呢 我们去找到就是接序的一个部分 大概在600这个地方的这个部分 好,找一下 好,这时候来讲说呢就是第一段来讲说呢 最透的一个时间就变成是这个16分38秒到16分的40秒 然后第二段呢就会从这个16分的40秒这个地方开始起. 所以这时候这个字幕就没有问题了 那字幕没有问题以后呢 接下来我们就把这个字幕我们把它下载下来 我们来看一看这个字幕我们今天把它上上去以后 它大概的一个效果如何 我们来看一下 那这边来讲说我们来用这个简易上一下字幕 来看一下这个地方的一个成果 那简易来讲说是一个很知名的一个软体 那现在有很多人去使用它来讲说去做免费上字幕的一个动作 那我们先来讲说因为要去介绍简易嘛 所以我们先用它来去上一下字幕 我们先把刚刚whisper转出来的这个字幕上上去 我们先来看一下效果如何 之后呢再透过这个简易的这个就是智能字幕 我们也去做一个版本出来 我们再来去做一个比较 好那这边呢你必须先去下载这个就是简易 下载下来以后呢这时候我们就打开这个就是简易专业版 然后我们开始做这个创作 首先必须导入我们的这个视频 所以我们就是这个导入以后选择这个jomain的这个mp4 我是先透过ytdlp然后先把它下载到就是我的本地端啦 所以这边讲说呢这本地端会有个mp4的一个档案 那之前的所教的是mp3的格式 所以如果说你要去下载mp4的话 必须把就是ytdlp的参数 改成就是下载mp4的一个参数 好下载完以后呢我们就把这个影片呢 就把它给拖到这个地方来 ok这边我们看到它的这个就是原始的这个影片 接下来呢这边我们必须把这个文本呢 把它给上载上去 所以我们选的就是文本 然后这边呢下面我们选的就是本地字幕 我们去导入srt的档案 我们把刚刚的这个就是merge subtitle这个srt 我们先把它给上载上去. 上载上去以后呢 我们就把这个文字档呢 我们要把它导入过来 ok切过来 好 这时候就导入了就是我们的这个就是文字 那导入这个文字以后呢 因为这个地方他原本就有上这个字幕嘛 然后这个颜色也不是很明显 所以就把这个颜色的这个字幕呢稍微改一下 我们把它改成就是黄色的好了 这边改一下 ok 然后这时候我们来去做这个播放 来去做这个比较 ok 所以这边我开始做这个播放 所以你们发现其实呢 whisper api做的这个效果呢真的是非常之好 好 那这边来讲说呢 去试过这个whisper api以后呢 接下来讲说这个简易呢 他自己有去提供这个就是智能字幕 透过ai上字幕 那他的呢是免费的 所以我们来看一下说这个简易的效果到底好不好 所以这边呢 如果说呢 就使用这个简易的智能字幕的话 我们就选择智能字幕 然后这边呢 我们讲说今天去让他去做这个字幕的识别 然后我们按下这个开始识别以后 让他来讲说呢 去做这个就是转换的一个动作 我们按一下 好 那现在已经转换完以后呢 这边呢 我也改一下就是这个字幕的这个颜色 所以这边说你看到这个就是简体中文的来讲说呢 就是简易转出来的这个结果 好 这边说呢 我们稍微去播放一下来去比较一下说他跟这个whisper api的一个差别 我们这一方去做个播放 ok 所以发现说呢 就是简易呢 其实效果也还不错 那只是来讲说呢 他第一个呢 是有产生这个简体中文的一个输出 第二个来讲说呢 其实在一些专有名词上面的一个翻译上面来讲说呢 其实做的并不是特别的好. 所以最后用起来的时候,我个人的感觉是这样子 如果今天对方说你要准确、快速地上字幕的话 whisper api是一个非常好的选择 这对方来讲说,它还可以透过prompt 来去提示今天是哪一个的主题 让他可以去做更精准的一个转录 它的优点很多,但是唯一的缺点就是它要钱 但是费用也不贵 大概是一个小时的影片,大概只要收10块钱的台币 那这算是什么概念呢? 如果你用过云端转录的一些服务 比如说我们讲雅庭竹子高号 它是收一个小时要100块 所以基本上来讲说,whisper api的横空出世 基本上是打趴了这一群原本做语音转文字的厂商 简易来讲说也很好 只是来讲说它有几个缺点 第一个是说它的翻译出来的结果 这一方来讲说是简体中文 当然你可以去做繁体中文的输出 但是用字遣词跟你平常所看到的 可能会稍微有一点点的一个不同 第二个来讲说,因为它没有办法根据domain跟主题 来让它去做一个比较精准的一些转录 所以在讲特定主题的时候 那个专有名词的翻译 还是会稍稍来讲说会有一些误差存在 第三个来讲说,其实它跟whisper api来讲说 它们最大的一个差别就是. 一个是api 所以如果说你今天想要去做大量的这个转入作文做这个语音分析的话 whisperapi是比较好的选择 那剪影的话就必须一支一支的影片 透过手动上载的一个方式再把字幕档拿出来 好所以这些来讲说呢大概就是这个就是whisperapi跟剪影的一个差别 但剪影呢来讲说呢有个很明显的好处就是 它不用钱是免费的 所以如果说今天你愿意花的时间 然后呢这地方你想要免费的去得到字幕的结果的话 那还是可以把剪影当成是一个好的上字幕的一个选择 好那以上来讲说呢就是我们今天对这个whisperapi 去如何去把这个就是语音转换成是字幕档的一个介绍 也去做了一些它跟剪影的一些相关的一些比较 那希望今天这个主题你喜欢 那如果说喜欢的话呢请就是帮我做这个订阅跟分享 谢谢. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# 定义要翻译的大文本\n",
        "text = audio_text\n",
        "\n",
        "# 将文本分割成较小的段落或句子\n",
        "segments = []\n",
        "segment_size = 800  # 每个段落的最大长度（以token为单位）\n",
        "\n",
        "for i in range(0, len(text), segment_size):\n",
        "    segment = text[i:i+segment_size]\n",
        "    segments.append(segment)\n",
        "\n",
        "# 使用线程池进行并发请求\n",
        "executor = ThreadPoolExecutor(max_workers=5)  # 根据需要调整并发请求数量\n",
        "\n",
        "# 上一个段落的翻译结果\n",
        "previous_translation = \"\"\n",
        "def translate_text_to_chinese(text):\n",
        "    # 声明为全局变量\n",
        "    global previous_translation\n",
        "\n",
        "    # 添加上一个段落的翻译结果作为上下文信息\n",
        "    translation = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=f\"根据下面的上下文，将以下英文文本翻译成中文: Context: '{previous_translation}' '{text}'\",\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "\n",
        "    translated_text = translation.choices[0].text.strip()\n",
        "    previous_translation = translated_text\n",
        "\n",
        "    return translated_text\n",
        "\n",
        "# 提交并发请求（逐个翻译每个段落）\n",
        "translated_segments = list(executor.map(translate_text_to_chinese, segments))\n",
        "\n",
        "# 合并翻译结果\n",
        "translated_text = ' '.join(translated_segments)\n",
        "\n",
        "print(translated_text)"
      ],
      "metadata": {
        "id": "XYiHsML97w2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b793a38-8084-42e6-b1b4-06b7a0bc78bf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "大家好，在上次的影片中我有介紹如何去利用Whisper將語音轉成文字，然後再利用Chaig GPT去進行摘要。之後有很多人問我如果有可能使用Whisper的API為影片製作字幕以及有關Whisper的API與簡映（快訊）的差別。 所以今天這集要一一去解答。首先，可以使用Whisper來為影片製作字幕，點擊whisper API的playground後，可以在documentation找到audio這個部分，這裡可以建立轉錄檔，他會吃參數，可以輸出字幕檔srt、verbal json或vtt等檔案。但是出現了一個問題，就是在安裝程式時缺少ffmpeg這個軟體。必須將ffmpeg下載安裝到電腦裡，之後才有辦法使用相關套件將YouTube AT上載影片轉換。 在這裡，我們對於下載YouTube影片以及對它進行一些轉換的動作，如果你沒有安裝ffmpeg這個套件的話，之前的程式碼會在此出現問題。ffmpeg的安裝雖然不是一鍵安裝，不過還是比較簡單的，你可以到官網去下載適用於不同作業系統版本的版本；安裝好以後，就可以使用ffmpeg進行操作了。如果今天覺得安裝ffmpeg過於複雜，可以考慮把程式碼放到codelab上，因為codelab預設ssh所開的vm都有預設裝載ffmpeg，所以我們可以在上面簡單地安裝ytdlp，下載YouTube的影片，並利用openai api對語音進行文字轉換。 翻译：我們將下載pip並安裝它，然後下載並安裝ytdlp、openai和pydub等相關套件。安裝完成後，我們將下載YouTube影片。我用codelab提供的表單稍加修改，就可以生成輸出檔案的名字。我們將Youtube連結輸入到右方選單裡。接著我們設定選項，將其輸出檔案名稱改為audio，並以mp3格式建立ytdop下載物件，最後再執行下載。最終在檔案序裡可以找到audio.mp3，然後使用quizper的api將音頻轉換成文字。由於quizper api的文件大小有限制，我們需要使用pydub來切割檔案，建議將檔案每個都切割為1000秒x1000解析度大約。 意思是100萬毫秒，因此我們今天將檔案分割成100萬毫秒，也就是1000秒。因此，如果這個影片超過20分鐘，它可能將分為16分鐘多一些的第一部分和約33分鐘的第二部分。為了做分割更方便，我們今天可以針對不同長度的影片做出不同的切割，例如20分鐘去切為兩部分，而40分鐘要分為三部分。然後，建立一個清單並使用回圈的方式切割，每次分割後產生的檔案分別為output0和output1.mp3，然後將其加入到soultrack清單中，並使用此程序切割影片，完成以後，將它分成output0.mp3和output1.mp3。接著，我們使用OpenAI的Whisper API將語音轉換為文字，將API的金鑰輸出為參數，然後再使用此參數將語音轉換為文字，最後再呼叫OpenAI的Audio.Transcribe，填入必要的參數，就可以產生字幕檔了。 來到這裡，我們要填兩個其他的東西：responseformat和prompt。先把responseformat填入，它是responseformat = srt。這樣，我今天就可以把這個輸出為字幕檔了，但是除了responseformat外，prompt也是需要填的。Prompt是一個提示詞，我們可以參考Speech-to-Text的Documentation去了解它什麼意思，它與Chair-GPT的Prompt有點不同，因為我們知道同一個音可能會有不同的意思，例如：如果今天講城堡這個字，金融領域可能會指的是保險，住宅領域可能會是山上城堡或歐洲城堡，因此我們可以使用Prompt來提示詞 去指明語音大概是關於哪一個主題，然後我們回到codelab，在後面加上一段Prompt = ，這裡我們可以輸入一段文字叫做“這是一段關於吳淡如與 Joema”。 翻譯：我們將下載PIP並安裝它，然後下載並安裝YTDLP、OpenAI和Pydub等相關套件。安裝完成後，我們將下載YouTube影片。我使用CodeLab提供的表單稍加修改，就可以生成輸出檔案的名稱。我們將YouTube連結輸入到右方選單裡。接著我們設定選項，將其輸出檔案名稱改為audio，並以mp3格式建立YTDOP下載物件，最後再執行下載。最終在檔案序裡可以找到audio.mp3，然後使用Quizper的API將音頻轉換成文字。由於Quizper API的文件大小有限制，我們需要使用Pydub來切割檔案，建議將檔案每個都切割為1000秒x1000解析度大約。討論台灣人是否應該買房的一個訪談，好，那我們加進去以後呢，這時候我們就大功告成，我們就產生了就是我們用的模型是Whisperone，然後呢這是我們的一個audio的檔案，我剛剛是把這個audio file是從我們的這個清單裡面來講說一一地取出以後去做這個轉換的動作，輸出的是我們這個就是字幕檔。最後來講說呢，我們把這個YouTube連結加上一個提示，告訴它講說這是一個關於買房的一個討論，叫它根據這樣子的一個主題去進行轉譯的一個動作。那我們就把這次每次產生出來的這個就是轉錄的這個腳本最後放到叫做transcripts底線ary這個清單之中，好，這邊講說我們去 在這裡，我們對於下載YouTube影片以及對它進行一些轉換的動作，如果你沒有安裝ffmpeg這個套件的話，之前的程式碼會在此出現問題。ffmpeg的安裝雖然不是一鍵安裝，不過還是比較簡單的，你可以到官網去下載適用於不同作業系統版本的版本；安裝好以後，就可以使用ffmpeg進行操作了。如果今天覺得安裝ffmpeg過於複雜，可以考慮把程式碼放到codelab上，因為codelab預設ssh所開的vm都有預設裝載ffmpeg，所以我們可以在上面簡單地安裝ytdlp，下載YouTube的影片，並利用openai api對語音進行文字轉換。\n",
            "\n",
            "然後我們接下來是做分段的轉錄，如果說我們今天想要把這兩個字幕檔今天把它給合併在一起的話，這時候我們該怎麼做？這時候就來講說我們就要去借助其他套件的幫忙，使用哪些套件呢？這時候很簡單的，我們就是直接把這個問題丟給chat gpt去進行回答，這時候我們就把它切換到chat gpt來問chat gpt來講說如何去合併兩個字幕檔。這邊我就直接打下我的敘述，就是如何使用python的pysrt套件，它是做一個字幕檔專門處理的套件來將兩個srt文件合併，並且去更改這個srt文件的時間戳。好，這邊我們來去做一個執行，這時候它就劈哩啪啦回了我一大堆告訴我講說我必須先去安裝這 來到這裡，我們要填兩個其他的東西：responseformat和prompt。先把responseformat填入，它是responseformat = srt。這樣，我今天就可以把這個輸出為字幕檔了，但是除了responseformat外，prompt也是需要填的。Prompt是一個提示詞，我們可以參考Speech-to-Text的Documentation去了解它什麼意思，它與Chair-GPT的Prompt有點不同，因為我們知道同一個音可能會有不同的意思，例如：如果今天講城堡這個字，金融領域可能會指的是保險，住宅領域可能會是山上城堡或歐洲城堡，因此我們可以使用Prompt來提示詞 去指明語音大概是關於哪一個主題，然後我們回到codelab，在後面加上一段Prompt = ，這裡我們可以輸入一段文字叫做“這是一段關於吳淡如與 Joema”。\n",
            "\n",
            "來到這裡，我們需要填入兩個內容：responseformat和prompt。先填入responseformat = srt，這樣就可以將輸出結果變成字幕檔了。除了responseformat外，也必須填入prompt，Prompt是一個提示詞，可以用於詳細指明語音的主題，因為同樣一個聲音可能有不同的意思。我們可以回到codelab，然後在後面加上一段Prompt = ，輸入一段文字“這是一段關於吳淡如與Joema”。 大家好，在上次的影片中，我介紹了如何使用Whisper將音訊轉換為文字，然後利用Chaig GPT進行摘要。之後有很多人問我，有沒有可能利用Whisper的API來製作影片字幕，以及Whisper的API和簡映（快訊）有什麼區別。所以今天，我們來一一解答這些問題。首先，可以使用Whisper來為影片製作字幕，登入Whisper API的Playground後，可以在Documentation找到\"audio\" 部分，在這裡可以建立一個轉錄檔，它可以接受參數並輸出字幕檔案，如srt，verbal json或vtt等檔案。但是會有一個問題：缺少ffmpeg這個軟體。因此要先將ffmpeg下載並安裝到電腦上，才能使用相關套件將YouTube上傳的影片轉換。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text_to_chinese(text):\n",
        "    translation = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=f\"将以下英文文本翻译成中文: '{text}'\",\n",
        "        max_tokens=1000,\n",
        "    )\n",
        "    translated_text = translation.choices[0].text.strip()\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "iRyj9jWC430s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chinese_audio_translation = translate_text_to_chinese(audio_text)\n",
        "print(\"\\nAudio Translate text:\", chinese_audio_translation)"
      ],
      "metadata": {
        "id": "aHj6U-8x4KQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c9b3ff-be4c-4283-c8da-2c5b2fdafff0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Audio Translate text: 你好，欢迎来到世界上最好的Python引导班。我叫安吉拉，是英国伦敦得分最高的编程引导培训学校 Appbury 的资深开发者和主要指导教师。迄今为止，我在现场和在线上教过超过50万名学生，我很高兴能作为你们的老师，教你们这门课程。作为本课程的学生，你们可以获得超过56小时的高清视频内容，其中包括一步一步的教程，互动编码练习，测验等等。 课程以100天的代码挑战为结构，所以你们可以期待着100天的坚持设计的内容，从Web开发到数据科学，涵盖了Python程序设计的方方面面。这是成为专业 Python 开发人员所需的唯一课程。每天上课时，你们都可以利用你们学到的东西来创建一个新项目。你们将构建一个机器人，在早晨给你发送短信，告诉你是否会下雨，这样你就永远不会忘记带雨伞了。你们将构建经典的街机游戏，像贪吃蛇和保龄球，以此来打动你的朋友，通过你自己设计的游戏来挑战他们。你们将学习理解复杂的数据，并创建出让你的同事印象深刻的美丽可视化图表。你们将创建一个程序，可以自动向你的朋友和家人发送生日祝福邮件.. 绝不会再忘记妈妈的生日了。你们将参与克隆现实世界初创公司的项目，廉价航班俱乐部？通过。建立你自己的博客？通过。推特机\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYGvMU5RMdCu5Ees6uHDul",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
